{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a0ed7a-a23a-4523-9171-f1d076700168",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%env DATA_BUCKET=tbd-2023z-9910-data\n",
    "%env GEN_OUTPUT_DIR=/tmp/tpc-di\n",
    "%env REPO_ROOT=/home/jupyter/git/tbd-tpc-di/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0fbec0d-d410-4de9-8dfd-00b07fdb7b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typer[All]==0.9.0 in /opt/conda/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: google-cloud-storage==2.13.0 in /opt/conda/lib/python3.10/site-packages (2.13.0)\n",
      "Collecting numpy==1.23.1\n",
      "  Downloading numpy-1.23.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m17.0/17.0 MB\u001B[0m \u001B[31m42.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer[All]==0.9.0) (8.1.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from typer[All]==0.9.0) (4.5.0)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from typer[All]==0.9.0) (0.4.6)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer[All]==0.9.0) (1.5.4)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer[All]==0.9.0) (13.3.5)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.23.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage==2.13.0) (2.24.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage==2.13.0) (2.14.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage==2.13.0) (2.3.2)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage==2.13.0) (2.6.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage==2.13.0) (2.28.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage==2.13.0) (1.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage==2.13.0) (1.59.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage==2.13.0) (4.25.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage==2.13.0) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage==2.13.0) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.23.3->google-cloud-storage==2.13.0) (4.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage==2.13.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage==2.13.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage==2.13.0) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage==2.13.0) (2022.12.7)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[All]==0.9.0) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[All]==0.9.0) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<14.0.0,>=10.11.0->typer[All]==0.9.0) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.23.3->google-cloud-storage==2.13.0) (0.5.0)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.5\n",
      "    Uninstalling numpy-1.23.5:\n",
      "      Successfully uninstalled numpy-1.23.5\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorboardx 2.6 requires protobuf<4,>=3.8.0, but you have protobuf 4.25.1 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0mSuccessfully installed numpy-1.23.1\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install typer[All]==0.9.0 google-cloud-storage==2.13.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697b5820-852d-4c30-a178-9dd78bbdbd5f",
   "metadata": {},
   "source": [
    "## Install SDKMAN for setting up JVM 8 enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3cdb5b-4978-479e-85c7-c9dbac3e65fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl -s https://get.sdkman.io | bash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691084f8-a883-408a-8d16-cc717669c04d",
   "metadata": {},
   "source": [
    "## Install and set as default JVM 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275488e6-68e3-4f42-a3ca-060b286bade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source \"$HOME/.sdkman/bin/sdkman-init.sh\"\n",
    "sdk install java 8.0.392-amzn\n",
    "sdk use java 8.0.392-amzn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3554db58-b832-45e2-a1f6-28bd873ae31d",
   "metadata": {},
   "source": [
    "## Check if JVM 8 is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898835b7-c347-49dd-bc0f-ca845375e1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source \"$HOME/.sdkman/bin/sdkman-init.sh\"\n",
    "java -version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e45d9a3-e599-4661-944b-1bdfe3808c19",
   "metadata": {},
   "source": [
    "## Clone tbd-tpc-di repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7481d445-4ea6-40cc-8320-5520fe8d4dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p git && cd git\n",
    "git clone https://github.com/mwiewior/tbd-tpc-di.git\n",
    "cd tbd-tpc-di\n",
    "git checkout feat/labs\n",
    "git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b992bfc-8f8c-42eb-bf07-069b0d897fda",
   "metadata": {},
   "source": [
    "## Generate input dataset (run this cell below from the terminal!!!)\n",
    "It should take approx. 15min with scale factor set to 100 and generate approx. 10GiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790ab901-15dc-4e94-b4fd-e2b9cfc6e012",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source \"$HOME/.sdkman/bin/sdkman-init.sh\"\n",
    "cd $REPO_ROOT/tools/\n",
    "java -jar DIGen.jar -sf 100 -o /tmp/tpc-di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a24c0aa-bff7-4831-869d-3183e7373a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and setup JVM 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e466e8-41aa-4afc-8392-5675d36adcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source \"$HOME/.sdkman/bin/sdkman-init.sh\"\n",
    "sdk install java 11.0.21-amzn\n",
    "sdk use java 11.0.21-amzn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dccda4c-40d4-40fe-9d2e-68b416522f64",
   "metadata": {},
   "source": [
    "## Load staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259b72bc-2efd-405b-883f-618a9772bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source \"$HOME/.sdkman/bin/sdkman-init.sh\"\n",
    "cd $REPO_ROOT\n",
    "python tpcdi.py --output-directory $GEN_OUTPUT_DIR --stage $DATA_BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0740193-5da4-4aac-9349-aa4e76f4e99b",
   "metadata": {},
   "source": [
    "## Run dbt ELT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98d0642c-b5c9-4aa8-996f-40f82e3c90e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[0m00:16:36  Running with dbt=1.7.3\n",
      "\u001B[0m00:16:37  Registered adapter: spark=1.7.1\n",
      "\u001B[0m00:16:37  [\u001B[33mWARNING\u001B[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.\n",
      "There are 4 unused configuration paths:\n",
      "- models.dbt_tpcdi.bronze\n",
      "- models.dbt_tpcdi.silver\n",
      "- models.dbt_tpcdi.gold\n",
      "- models.dbt_tpcdi.work\n",
      "\u001B[0m00:16:37  Found 45 models, 1 test, 17 sources, 0 exposures, 0 metrics, 553 macros, 0 groups, 0 semantic models\n",
      "\u001B[0m00:16:37  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.hadoop.shaded.org.xbill.DNS.ResolverConfig (file:/opt/conda/lib/python3.10/site-packages/pyspark/jars/hadoop-client-runtime-3.3.2.jar) to method sun.net.dns.ResolverConfiguration.open()\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.shaded.org.xbill.DNS.ResolverConfig\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/12/04 00:16:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/12/04 00:16:52 WARN HiveClientImpl: Detected HiveConf hive.execution.engine is 'tez' and will be reset to 'mr' to disable useless hive logic\n",
      "\u001B[0m00:16:55  Concurrency: 1 threads (target='dev')\n",
      "\u001B[0m00:16:55  \n",
      "\u001B[0m00:16:55  1 of 45 START sql view model bronze.brokerage_cash_transaction ................. [RUN]\n",
      "23/12/04 00:16:56 WARN DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.\n",
      "23/12/04 00:16:57 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
      "\u001B[0m00:16:57  1 of 45 OK created sql view model bronze.brokerage_cash_transaction ............ [\u001B[32mOK\u001B[0m in 1.99s]\n",
      "\u001B[0m00:16:57  2 of 45 START sql view model bronze.brokerage_daily_market ..................... [RUN]\n",
      "\u001B[0m00:16:58  2 of 45 OK created sql view model bronze.brokerage_daily_market ................ [\u001B[32mOK\u001B[0m in 0.51s]\n",
      "\u001B[0m00:16:58  3 of 45 START sql view model bronze.brokerage_holding_history .................. [RUN]\n",
      "\u001B[0m00:16:58  3 of 45 OK created sql view model bronze.brokerage_holding_history ............. [\u001B[32mOK\u001B[0m in 0.45s]\n",
      "\u001B[0m00:16:58  4 of 45 START sql view model bronze.brokerage_trade ............................ [RUN]\n",
      "\u001B[0m00:16:59  4 of 45 OK created sql view model bronze.brokerage_trade ....................... [\u001B[32mOK\u001B[0m in 0.45s]\n",
      "\u001B[0m00:16:59  5 of 45 START sql view model bronze.brokerage_trade_history .................... [RUN]\n",
      "\u001B[0m00:16:59  5 of 45 OK created sql view model bronze.brokerage_trade_history ............... [\u001B[32mOK\u001B[0m in 0.35s]\n",
      "\u001B[0m00:16:59  6 of 45 START sql view model bronze.brokerage_watch_history .................... [RUN]\n",
      "\u001B[0m00:16:59  6 of 45 OK created sql view model bronze.brokerage_watch_history ............... [\u001B[32mOK\u001B[0m in 0.45s]\n",
      "\u001B[0m00:16:59  7 of 45 START sql view model bronze.crm_customer_mgmt .......................... [RUN]\n",
      "23/12/04 00:17:00 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "\u001B[0m00:17:00  7 of 45 OK created sql view model bronze.crm_customer_mgmt ..................... [\u001B[32mOK\u001B[0m in 0.87s]\n",
      "\u001B[0m00:17:00  8 of 45 START sql view model bronze.finwire_company ............................ [RUN]\n",
      "\u001B[0m00:17:01  8 of 45 OK created sql view model bronze.finwire_company ....................... [\u001B[32mOK\u001B[0m in 0.50s]\n",
      "\u001B[0m00:17:01  9 of 45 START sql view model bronze.finwire_financial .......................... [RUN]\n",
      "\u001B[0m00:17:02  9 of 45 OK created sql view model bronze.finwire_financial ..................... [\u001B[32mOK\u001B[0m in 1.11s]\n",
      "\u001B[0m00:17:02  10 of 45 START sql view model bronze.finwire_security .......................... [RUN]\n",
      "\u001B[0m00:17:03  10 of 45 OK created sql view model bronze.finwire_security ..................... [\u001B[32mOK\u001B[0m in 0.70s]\n",
      "\u001B[0m00:17:03  11 of 45 START sql view model bronze.hr_employee ............................... [RUN]\n",
      "\u001B[0m00:17:03  11 of 45 OK created sql view model bronze.hr_employee .......................... [\u001B[32mOK\u001B[0m in 0.54s]\n",
      "\u001B[0m00:17:03  12 of 45 START sql view model bronze.reference_date ............................ [RUN]\n",
      "\u001B[0m00:17:04  12 of 45 OK created sql view model bronze.reference_date ....................... [\u001B[32mOK\u001B[0m in 0.57s]\n",
      "\u001B[0m00:17:04  13 of 45 START sql view model bronze.reference_industry ........................ [RUN]\n",
      "\u001B[0m00:17:04  13 of 45 OK created sql view model bronze.reference_industry ................... [\u001B[32mOK\u001B[0m in 0.48s]\n",
      "\u001B[0m00:17:04  14 of 45 START sql view model bronze.reference_status_type ..................... [RUN]\n",
      "\u001B[0m00:17:05  14 of 45 OK created sql view model bronze.reference_status_type ................ [\u001B[32mOK\u001B[0m in 0.47s]\n",
      "\u001B[0m00:17:05  15 of 45 START sql view model bronze.reference_tax_rate ........................ [RUN]\n",
      "\u001B[0m00:17:05  15 of 45 OK created sql view model bronze.reference_tax_rate ................... [\u001B[32mOK\u001B[0m in 0.46s]\n",
      "\u001B[0m00:17:05  16 of 45 START sql view model bronze.reference_trade_type ...................... [RUN]\n",
      "\u001B[0m00:17:06  16 of 45 OK created sql view model bronze.reference_trade_type ................. [\u001B[32mOK\u001B[0m in 0.48s]\n",
      "\u001B[0m00:17:06  17 of 45 START sql view model bronze.syndicated_prospect ....................... [RUN]\n",
      "\u001B[0m00:17:06  17 of 45 OK created sql view model bronze.syndicated_prospect .................. [\u001B[32mOK\u001B[0m in 0.48s]\n",
      "\u001B[0m00:17:06  18 of 45 START sql view model bronze.daily_market .............................. [RUN]\n",
      "\u001B[0m00:17:07  18 of 45 OK created sql view model bronze.daily_market ......................... [\u001B[32mOK\u001B[0m in 1.09s]\n",
      "\u001B[0m00:17:07  19 of 45 START sql view model bronze.employees ................................. [RUN]\n",
      "\u001B[0m00:17:08  19 of 45 OK created sql view model bronze.employees ............................ [\u001B[32mOK\u001B[0m in 0.38s]\n",
      "\u001B[0m00:17:08  20 of 45 START sql view model bronze.date ...................................... [RUN]\n",
      "\u001B[0m00:17:08  20 of 45 OK created sql view model bronze.date ................................. [\u001B[32mOK\u001B[0m in 0.47s]\n",
      "\u001B[0m00:17:08  21 of 45 START sql view model bronze.companies ................................. [RUN]\n",
      "\u001B[0m00:17:09  21 of 45 OK created sql view model bronze.companies ............................ [\u001B[32mOK\u001B[0m in 0.95s]\n",
      "\u001B[0m00:17:09  22 of 45 START sql view model bronze.accounts .................................. [RUN]\n",
      "\u001B[0m00:17:10  22 of 45 OK created sql view model bronze.accounts ............................. [\u001B[32mOK\u001B[0m in 1.01s]\n",
      "\u001B[0m00:17:10  23 of 45 START sql view model bronze.customers ................................. [RUN]\n",
      "\u001B[0m00:17:12  23 of 45 OK created sql view model bronze.customers ............................ [\u001B[32mOK\u001B[0m in 0.85s]\n",
      "\u001B[0m00:17:12  24 of 45 START sql view model bronze.trades_history ............................ [RUN]\n",
      "\u001B[0m00:17:12  24 of 45 OK created sql view model bronze.trades_history ....................... [\u001B[32mOK\u001B[0m in 0.89s]\n",
      "\u001B[0m00:17:12  25 of 45 START sql view model bronze.dim_broker ................................ [RUN]\n",
      "\u001B[0m00:17:13  25 of 45 OK created sql view model bronze.dim_broker ........................... [\u001B[32mOK\u001B[0m in 0.50s]\n",
      "\u001B[0m00:17:13  26 of 45 START sql view model bronze.dim_date .................................. [RUN]\n",
      "\u001B[0m00:17:13  26 of 45 OK created sql view model bronze.dim_date ............................. [\u001B[32mOK\u001B[0m in 0.52s]\n",
      "\u001B[0m00:17:14  27 of 45 START sql view model bronze.dim_company ............................... [RUN]\n",
      "\u001B[0m00:17:14  27 of 45 OK created sql view model bronze.dim_company .......................... [\u001B[32mOK\u001B[0m in 0.88s]\n",
      "\u001B[0m00:17:14  28 of 45 START sql view model bronze.financials ................................ [RUN]\n",
      "\u001B[0m00:17:16  28 of 45 OK created sql view model bronze.financials ........................... [\u001B[32mOK\u001B[0m in 1.56s]\n",
      "\u001B[0m00:17:16  29 of 45 START sql view model bronze.securities ................................ [RUN]\n",
      "\u001B[0m00:17:17  29 of 45 OK created sql view model bronze.securities ........................... [\u001B[32mOK\u001B[0m in 1.37s]\n",
      "\u001B[0m00:17:17  30 of 45 START sql view model bronze.cash_transactions ......................... [RUN]\n",
      "\u001B[0m00:17:18  30 of 45 OK created sql view model bronze.cash_transactions .................... [\u001B[32mOK\u001B[0m in 0.90s]\n",
      "\u001B[0m00:17:18  31 of 45 START sql view model bronze.dim_customer .............................. [RUN]\n",
      "\u001B[0m00:17:20  31 of 45 OK created sql view model bronze.dim_customer ......................... [\u001B[32mOK\u001B[0m in 1.25s]\n",
      "\u001B[0m00:17:20  32 of 45 START sql view model bronze.dim_trade ................................. [RUN]\n",
      "\u001B[0m00:17:21  32 of 45 OK created sql view model bronze.dim_trade ............................ [\u001B[32mOK\u001B[0m in 0.98s]\n",
      "\u001B[0m00:17:21  33 of 45 START sql view model bronze.trades .................................... [RUN]\n",
      "\u001B[0m00:17:21  33 of 45 OK created sql view model bronze.trades ............................... [\u001B[32mOK\u001B[0m in 0.96s]\n",
      "\u001B[0m00:17:21  34 of 45 START sql view model bronze.wrk_company_financials .................... [RUN]\n",
      "\u001B[0m00:17:23  34 of 45 OK created sql view model bronze.wrk_company_financials ............... [\u001B[32mOK\u001B[0m in 1.63s]\n",
      "\u001B[0m00:17:23  35 of 45 START sql view model bronze.dim_security .............................. [RUN]\n",
      "\u001B[0m00:17:25  35 of 45 OK created sql view model bronze.dim_security ......................... [\u001B[32mOK\u001B[0m in 1.55s]\n",
      "\u001B[0m00:17:25  36 of 45 START sql view model bronze.watches_history ........................... [RUN]\n",
      "\u001B[0m00:17:26  36 of 45 OK created sql view model bronze.watches_history ...................... [\u001B[32mOK\u001B[0m in 1.33s]\n",
      "\u001B[0m00:17:26  37 of 45 START sql view model bronze.dim_account ............................... [RUN]\n",
      "\u001B[0m00:17:28  37 of 45 OK created sql view model bronze.dim_account .......................... [\u001B[32mOK\u001B[0m in 2.10s]\n",
      "\u001B[0m00:17:28  38 of 45 START sql view model bronze.holdings_history .......................... [RUN]\n",
      "\u001B[0m00:17:29  38 of 45 OK created sql view model bronze.holdings_history ..................... [\u001B[32mOK\u001B[0m in 1.13s]\n",
      "\u001B[0m00:17:29  39 of 45 START sql view model bronze.fact_market_history ....................... [RUN]\n",
      "\u001B[0m00:17:32  39 of 45 OK created sql view model bronze.fact_market_history .................. [\u001B[32mOK\u001B[0m in 3.15s]\n",
      "\u001B[0m00:17:32  40 of 45 START sql view model bronze.watches ................................... [RUN]\n",
      "\u001B[0m00:17:34  40 of 45 OK created sql view model bronze.watches .............................. [\u001B[32mOK\u001B[0m in 1.50s]\n",
      "\u001B[0m00:17:34  41 of 45 START sql view model bronze.fact_cash_transactions .................... [RUN]\n",
      "\u001B[0m00:17:36  41 of 45 OK created sql view model bronze.fact_cash_transactions ............... [\u001B[32mOK\u001B[0m in 2.39s]\n",
      "\u001B[0m00:17:36  42 of 45 START sql view model bronze.fact_trade ................................ [RUN]\n",
      "\u001B[0m00:17:40  42 of 45 OK created sql view model bronze.fact_trade ........................... [\u001B[32mOK\u001B[0m in 4.02s]\n",
      "\u001B[0m00:17:40  43 of 45 START sql view model bronze.fact_holdings ............................. [RUN]\n",
      "\u001B[0m00:17:45  43 of 45 OK created sql view model bronze.fact_holdings ........................ [\u001B[32mOK\u001B[0m in 4.89s]\n",
      "\u001B[0m00:17:45  44 of 45 START sql view model bronze.fact_watches .............................. [RUN]\n",
      "\u001B[0m00:17:49  44 of 45 OK created sql view model bronze.fact_watches ......................... [\u001B[32mOK\u001B[0m in 3.80s]\n",
      "\u001B[0m00:17:49  45 of 45 START sql view model bronze.fact_cash_balances ........................ [RUN]\n",
      "\u001B[0m00:17:52  45 of 45 OK created sql view model bronze.fact_cash_balances ................... [\u001B[32mOK\u001B[0m in 2.52s]\n",
      "\u001B[0m00:17:52  \n",
      "\u001B[0m00:17:52  Finished running 45 view models in 0 hours 1 minutes and 14.34 seconds (74.34s).\n",
      "\u001B[0m00:17:52  \n",
      "\u001B[0m00:17:52  \u001B[32mCompleted successfully\u001B[0m\n",
      "\u001B[0m00:17:52  \n",
      "\u001B[0m00:17:52  Done. PASS=45 WARN=0 ERROR=0 SKIP=0 TOTAL=45\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd $REPO_ROOT/tools/\n",
    "dbt run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae93304-68eb-46c8-86a3-26feec06a54a",
   "metadata": {},
   "source": [
    "## Run dbt tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6b563f4-0b31-40a3-b353-9e6c9de8c482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[0m00:19:46  Running with dbt=1.7.3\n",
      "\u001B[0m00:19:47  Registered adapter: spark=1.7.1\n",
      "\u001B[0m00:19:48  [\u001B[33mWARNING\u001B[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.\n",
      "There are 4 unused configuration paths:\n",
      "- models.dbt_tpcdi.gold\n",
      "- models.dbt_tpcdi.bronze\n",
      "- models.dbt_tpcdi.work\n",
      "- models.dbt_tpcdi.silver\n",
      "\u001B[0m00:19:48  Found 45 models, 1 test, 17 sources, 0 exposures, 0 metrics, 553 macros, 0 groups, 0 semantic models\n",
      "\u001B[0m00:19:48  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.hadoop.shaded.org.xbill.DNS.ResolverConfig (file:/opt/conda/lib/python3.10/site-packages/pyspark/jars/hadoop-client-runtime-3.3.2.jar) to method sun.net.dns.ResolverConfiguration.open()\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.shaded.org.xbill.DNS.ResolverConfig\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/12/04 00:19:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/12/04 00:20:01 WARN HiveClientImpl: Detected HiveConf hive.execution.engine is 'tez' and will be reset to 'mr' to disable useless hive logic\n",
      "\u001B[0m00:20:06  Concurrency: 1 threads (target='dev')\n",
      "\u001B[0m00:20:06  \n",
      "\u001B[0m00:20:06  1 of 1 START test fact_trade__unique_trade ..................................... [RUN]\n",
      "23/12/04 00:20:08 WARN DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.\n",
      "\u001B[0m00:21:45  1 of 1 PASS fact_trade__unique_trade ........................................... [\u001B[32mPASS\u001B[0m in 98.69s]\n",
      "\u001B[0m00:21:45  \n",
      "\u001B[0m00:21:45  Finished running 1 test in 0 hours 1 minutes and 57.07 seconds (117.07s).\n",
      "\u001B[0m00:21:45  \n",
      "\u001B[0m00:21:45  \u001B[32mCompleted successfully\u001B[0m\n",
      "\u001B[0m00:21:45  \n",
      "\u001B[0m00:21:45  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd $REPO_ROOT/tools/\n",
    "dbt test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6ce00fe-ce46-4202-a798-a7f227ff3c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.hadoop.shaded.org.xbill.DNS.ResolverConfig (file:/usr/local/lib/python3.8/dist-packages/pyspark/jars/hadoop-client-runtime-3.3.2.jar) to method sun.net.dns.ResolverConfiguration.open()\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.shaded.org.xbill.DNS.ResolverConfig\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/12/04 00:26:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/12/04 00:26:38 WARN DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.\n",
      "23/12/04 00:26:38 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TBD-TPC-DI-setup\") \\\n",
    "    .master(\"yarn\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c892605-9496-4526-b574-a19168678934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/12/04 00:27:49 WARN HiveClientImpl: Detected HiveConf hive.execution.engine is 'tez' and will be reset to 'mr' to disable useless hive logic\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>namespace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>digen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>silver</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  namespace\n",
       "0    bronze\n",
       "1   default\n",
       "2     digen\n",
       "3      gold\n",
       "4    silver"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"show databases\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2e94c83-4983-49f5-8597-77e3b9c4661c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"use demp_gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44296edd-82e6-4600-b730-d2cc4992a81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|   bronze|            accounts|      false|\n",
      "|   bronze|brokerage_cash_tr...|      false|\n",
      "|   bronze|brokerage_daily_m...|      false|\n",
      "|   bronze|brokerage_holding...|      false|\n",
      "|   bronze|     brokerage_trade|      false|\n",
      "|   bronze|brokerage_trade_h...|      false|\n",
      "|   bronze|brokerage_watch_h...|      false|\n",
      "|   bronze|   cash_transactions|      false|\n",
      "|   bronze|           companies|      false|\n",
      "|   bronze|   crm_customer_mgmt|      false|\n",
      "|   bronze|           customers|      false|\n",
      "|   bronze|        daily_market|      false|\n",
      "|   bronze|                date|      false|\n",
      "|   bronze|         dim_account|      false|\n",
      "|   bronze|          dim_broker|      false|\n",
      "|   bronze|         dim_company|      false|\n",
      "|   bronze|        dim_customer|      false|\n",
      "|   bronze|            dim_date|      false|\n",
      "|   bronze|        dim_security|      false|\n",
      "|   bronze|           dim_trade|      false|\n",
      "+---------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e34fa44-084c-4445-ad41-17b4762a0446",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c190b0c0-b4e2-4aed-85aa-1b78b77d1c05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
