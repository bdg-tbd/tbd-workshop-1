{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90a0ed7a-a23a-4523-9171-f1d076700168",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DATA_BUCKET=tbd-2023z-9910-data\n",
      "env: GEN_OUTPUT_DIR=/tmp/tpc-di\n",
      "env: REPO_ROOT=/home/jupyter/git/tbd-tpc-di/\n"
     ]
    }
   ],
   "source": [
    "%env DATA_BUCKET=tbd-2023z-9910-data\n",
    "%env GEN_OUTPUT_DIR=/tmp/tpc-di\n",
    "%env REPO_ROOT=/home/jupyter/git/tbd-tpc-di/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fbec0d-d410-4de9-8dfd-00b07fdb7b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3.8 install typer[All]==0.9.0 google-cloud-storage==2.13.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697b5820-852d-4c30-a178-9dd78bbdbd5f",
   "metadata": {},
   "source": [
    "## Install SDKMAN for setting up JVM 8 enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3cdb5b-4978-479e-85c7-c9dbac3e65fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl -s https://get.sdkman.io | bash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691084f8-a883-408a-8d16-cc717669c04d",
   "metadata": {},
   "source": [
    "## Install and set as default JVM 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275488e6-68e3-4f42-a3ca-060b286bade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source \"$HOME/.sdkman/bin/sdkman-init.sh\"\n",
    "sdk install java 8.0.392-amzn\n",
    "sdk use java 8.0.392-amzn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3554db58-b832-45e2-a1f6-28bd873ae31d",
   "metadata": {},
   "source": [
    "## Check if JVM 8 is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898835b7-c347-49dd-bc0f-ca845375e1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source \"$HOME/.sdkman/bin/sdkman-init.sh\"\n",
    "java -version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e45d9a3-e599-4661-944b-1bdfe3808c19",
   "metadata": {},
   "source": [
    "## Clone tbd-tpc-di repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7481d445-4ea6-40cc-8320-5520fe8d4dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p git && cd git\n",
    "git clone https://github.com/mwiewior/tbd-tpc-di.git\n",
    "cd tbd-tpc-di\n",
    "git checkout feat/labs\n",
    "git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b992bfc-8f8c-42eb-bf07-069b0d897fda",
   "metadata": {},
   "source": [
    "## Generate input dataset (run this cell below from the terminal!!!)\n",
    "It should take approx. 15min with scale factor set to 100 and generate approx. 10GiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790ab901-15dc-4e94-b4fd-e2b9cfc6e012",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "source \"$HOME/.sdkman/bin/sdkman-init.sh\"\n",
    "cd /home/jupyter/git/tbd-tpc-di/tools/ \n",
    "java -jar DIGen.jar -sf 100 -o /tmp/tpc-di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a24c0aa-bff7-4831-869d-3183e7373a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and setup JVM 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e466e8-41aa-4afc-8392-5675d36adcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source \"$HOME/.sdkman/bin/sdkman-init.sh\"\n",
    "sdk install java 11.0.21-amzn\n",
    "sdk use java 11.0.21-amzn -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dccda4c-40d4-40fe-9d2e-68b416522f64",
   "metadata": {},
   "source": [
    "## Load staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259b72bc-2efd-405b-883f-618a9772bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source \"$HOME/.sdkman/bin/sdkman-init.sh\"\n",
    "cd $REPO_ROOT\n",
    "python3.8 tpcdi.py --output-directory $GEN_OUTPUT_DIR --stage $DATA_BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c641262-c34a-48af-b5db-3152c31ae219",
   "metadata": {},
   "source": [
    "## Setup dbt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9232345b-b306-4eb1-892d-b572e50e8e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $REPO_ROOT\n",
    "pip3.8 install -r requirements.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a45657-ba75-405e-912f-fce43c2b2530",
   "metadata": {},
   "source": [
    "## Test dbt connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8829f78-8775-42da-85cf-ab1d8d51d1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $REPO_ROOT\n",
    "dbt debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5abb5f9-fd19-423d-af18-136e7125e753",
   "metadata": {},
   "source": [
    "## Install dbt deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c97fb5b-6860-4d96-bde5-4ca1e7b97699",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $REPO_ROOT\n",
    "dbt deps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0740193-5da4-4aac-9349-aa4e76f4e99b",
   "metadata": {},
   "source": [
    "## Run dbt ELT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d0642c-b5c9-4aa8-996f-40f82e3c90e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m11:42:04  Running with dbt=1.7.3\n",
      "\u001b[0m11:42:05  Registered adapter: spark=1.7.1\n",
      "\u001b[0m11:42:06  Found 45 models, 1 test, 17 sources, 0 exposures, 0 metrics, 553 macros, 0 groups, 0 semantic models\n",
      "\u001b[0m11:42:06  \n",
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.8/dist-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "com.databricks#spark-xml_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-2c86d8ea-06c9-4950-a58a-c8d01780922e;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.databricks#spark-xml_2.12;0.17.0 in central\n",
      "\tfound commons-io#commons-io;2.11.0 in central\n",
      "\tfound org.glassfish.jaxb#txw2;3.0.2 in central\n",
      "\tfound org.apache.ws.xmlschema#xmlschema-core;2.3.0 in central\n",
      "\tfound org.scala-lang.modules#scala-collection-compat_2.12;2.9.0 in central\n",
      ":: resolution report :: resolve 571ms :: artifacts dl 23ms\n",
      "\t:: modules in use:\n",
      "\tcom.databricks#spark-xml_2.12;0.17.0 from central in [default]\n",
      "\tcommons-io#commons-io;2.11.0 from central in [default]\n",
      "\torg.apache.ws.xmlschema#xmlschema-core;2.3.0 from central in [default]\n",
      "\torg.glassfish.jaxb#txw2;3.0.2 from central in [default]\n",
      "\torg.scala-lang.modules#scala-collection-compat_2.12;2.9.0 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-2c86d8ea-06c9-4950-a58a-c8d01780922e\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 5 already retrieved (0kB/13ms)\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.hadoop.shaded.org.xbill.DNS.ResolverConfig (file:/usr/local/lib/python3.8/dist-packages/pyspark/jars/hadoop-client-runtime-3.3.2.jar) to method sun.net.dns.ResolverConfiguration.open()\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.shaded.org.xbill.DNS.ResolverConfig\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/12/04 11:42:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/12/04 11:42:16 WARN DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.\n",
      "23/12/04 11:42:16 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "23/12/04 11:42:24 WARN Client: Same path resource file:///root/.ivy2/jars/com.databricks_spark-xml_2.12-0.17.0.jar added multiple times to distributed cache.\n",
      "23/12/04 11:42:24 WARN Client: Same path resource file:///root/.ivy2/jars/commons-io_commons-io-2.11.0.jar added multiple times to distributed cache.\n",
      "23/12/04 11:42:24 WARN Client: Same path resource file:///root/.ivy2/jars/org.glassfish.jaxb_txw2-3.0.2.jar added multiple times to distributed cache.\n",
      "23/12/04 11:42:24 WARN Client: Same path resource file:///root/.ivy2/jars/org.apache.ws.xmlschema_xmlschema-core-2.3.0.jar added multiple times to distributed cache.\n",
      "23/12/04 11:42:24 WARN Client: Same path resource file:///root/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.9.0.jar added multiple times to distributed cache.\n",
      "23/12/04 11:42:51 WARN HiveClientImpl: Detected HiveConf hive.execution.engine is 'tez' and will be reset to 'mr' to disable useless hive logic\n",
      "\u001b[0m11:42:54  Concurrency: 1 threads (target='dev')\n",
      "\u001b[0m11:42:54  \n",
      "\u001b[0m11:42:54  1 of 44 START sql table model demo_bronze.brokerage_cash_transaction ........... [RUN]\n",
      "23/12/04 11:42:55 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "23/12/04 11:42:56 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
      "\u001b[0m11:43:42  1 of 44 OK created sql table model demo_bronze.brokerage_cash_transaction ...... [\u001b[32mOK\u001b[0m in 47.86s]\n",
      "\u001b[0m11:43:42  2 of 44 START sql table model demo_bronze.brokerage_daily_market ............... [RUN]\n",
      "23/12/04 11:43:43 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m11:45:18  2 of 44 OK created sql table model demo_bronze.brokerage_daily_market .......... [\u001b[32mOK\u001b[0m in 95.55s]\n",
      "\u001b[0m11:45:18  3 of 44 START sql table model demo_bronze.brokerage_holding_history ............ [RUN]\n",
      "23/12/04 11:45:18 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m11:45:31  3 of 44 OK created sql table model demo_bronze.brokerage_holding_history ....... [\u001b[32mOK\u001b[0m in 13.22s]\n",
      "\u001b[0m11:45:31  4 of 44 START sql table model demo_bronze.brokerage_trade ...................... [RUN]\n",
      "23/12/04 11:45:31 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m11:46:26  4 of 44 OK created sql table model demo_bronze.brokerage_trade ................. [\u001b[32mOK\u001b[0m in 55.21s]\n",
      "\u001b[0m11:46:26  5 of 44 START sql table model demo_bronze.brokerage_trade_history .............. [RUN]\n",
      "23/12/04 11:46:26 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m11:47:16  5 of 44 OK created sql table model demo_bronze.brokerage_trade_history ......... [\u001b[32mOK\u001b[0m in 49.64s]\n",
      "\u001b[0m11:47:16  6 of 44 START sql table model demo_bronze.brokerage_watch_history .............. [RUN]\n",
      "23/12/04 11:47:16 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m11:48:09  6 of 44 OK created sql table model demo_bronze.brokerage_watch_history ......... [\u001b[32mOK\u001b[0m in 52.93s]\n",
      "\u001b[0m11:48:09  7 of 44 START sql table model demo_bronze.crm_customer_mgmt .................... [RUN]\n",
      "23/12/04 11:48:09 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "23/12/04 11:48:09 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "\u001b[0m11:48:18  7 of 44 OK created sql table model demo_bronze.crm_customer_mgmt ............... [\u001b[32mOK\u001b[0m in 9.71s]\n",
      "\u001b[0m11:48:18  8 of 44 START sql table model demo_bronze.finwire_company ...................... [RUN]\n",
      "23/12/04 11:48:19 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m11:48:21  8 of 44 OK created sql table model demo_bronze.finwire_company ................. [\u001b[32mOK\u001b[0m in 3.00s]\n",
      "\u001b[0m11:48:21  9 of 44 START sql table model demo_bronze.finwire_financial .................... [RUN]\n",
      "23/12/04 11:48:22 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m11:49:26  9 of 44 OK created sql table model demo_bronze.finwire_financial ............... [\u001b[32mOK\u001b[0m in 64.19s]\n",
      "\u001b[0m11:49:26  10 of 44 START sql table model demo_bronze.finwire_security .................... [RUN]\n",
      "23/12/04 11:49:26 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m11:49:28  10 of 44 OK created sql table model demo_bronze.finwire_security ............... [\u001b[32mOK\u001b[0m in 2.87s]\n",
      "\u001b[0m11:49:28  11 of 44 START sql table model demo_bronze.hr_employee ......................... [RUN]\n",
      "23/12/04 11:49:29 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m11:49:32  11 of 44 OK created sql table model demo_bronze.hr_employee .................... [\u001b[32mOK\u001b[0m in 3.07s]\n",
      "\u001b[0m11:49:32  12 of 44 START sql table model demo_bronze.reference_date ...................... [RUN]\n",
      "23/12/04 11:49:32 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m11:49:33  12 of 44 OK created sql table model demo_bronze.reference_date ................. [\u001b[32mOK\u001b[0m in 1.50s]\n",
      "\u001b[0m11:49:33  13 of 44 START sql table model demo_bronze.reference_industry .................. [RUN]\n",
      "23/12/04 11:49:33 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m11:49:34  13 of 44 OK created sql table model demo_bronze.reference_industry ............. [\u001b[32mOK\u001b[0m in 1.08s]\n",
      "\u001b[0m11:49:34  14 of 44 START sql table model demo_bronze.reference_status_type ............... [RUN]\n",
      "23/12/04 11:49:35 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m11:49:35  14 of 44 OK created sql table model demo_bronze.reference_status_type .......... [\u001b[32mOK\u001b[0m in 1.02s]\n",
      "\u001b[0m11:49:35  15 of 44 START sql table model demo_bronze.reference_tax_rate .................. [RUN]\n",
      "23/12/04 11:49:36 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m11:49:37  15 of 44 OK created sql table model demo_bronze.reference_tax_rate ............. [\u001b[32mOK\u001b[0m in 1.46s]\n",
      "\u001b[0m11:49:37  16 of 44 START sql table model demo_bronze.reference_trade_type ................ [RUN]\n",
      "23/12/04 11:49:37 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m11:49:38  16 of 44 OK created sql table model demo_bronze.reference_trade_type ........... [\u001b[32mOK\u001b[0m in 1.03s]\n",
      "\u001b[0m11:49:38  17 of 44 START sql table model demo_bronze.syndicated_prospect ................. [RUN]\n",
      "23/12/04 11:49:38 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m11:49:44  17 of 44 OK created sql table model demo_bronze.syndicated_prospect ............ [\u001b[32mOK\u001b[0m in 6.13s]\n",
      "\u001b[0m11:49:44  18 of 44 START sql table model demo_silver.daily_market ........................ [RUN]\n",
      "23/12/04 11:49:44 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m12:09:27  18 of 44 OK created sql table model demo_silver.daily_market ................... [\u001b[32mOK\u001b[0m in 1183.44s]\n",
      "\u001b[0m12:09:27  19 of 44 START sql table model demo_silver.employees ........................... [RUN]\n",
      "23/12/04 12:09:27 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m12:09:31  19 of 44 OK created sql table model demo_silver.employees ...................... [\u001b[32mOK\u001b[0m in 4.07s]\n",
      "\u001b[0m12:09:31  20 of 44 START sql table model demo_silver.date ................................ [RUN]\n",
      "23/12/04 12:09:32 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m12:09:33  20 of 44 OK created sql table model demo_silver.date ........................... [\u001b[32mOK\u001b[0m in 1.77s]\n",
      "\u001b[0m12:09:33  21 of 44 START sql table model demo_silver.companies ........................... [RUN]\n",
      "23/12/04 12:09:33 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m12:09:40  21 of 44 OK created sql table model demo_silver.companies ...................... [\u001b[32mOK\u001b[0m in 6.44s]\n",
      "\u001b[0m12:09:40  22 of 44 START sql table model demo_silver.accounts ............................ [RUN]\n",
      "23/12/04 12:09:40 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m12:09:53  22 of 44 OK created sql table model demo_silver.accounts ....................... [\u001b[32mOK\u001b[0m in 13.21s]\n",
      "\u001b[0m12:09:53  23 of 44 START sql table model demo_silver.customers ........................... [RUN]\n",
      "23/12/04 12:09:53 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m12:10:03  23 of 44 OK created sql table model demo_silver.customers ...................... [\u001b[32mOK\u001b[0m in 9.80s]\n",
      "\u001b[0m12:10:03  24 of 44 START sql table model demo_silver.trades_history ...................... [RUN]\n",
      "23/12/04 12:10:04 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m12:15:06  24 of 44 OK created sql table model demo_silver.trades_history ................. [\u001b[32mOK\u001b[0m in 302.65s]\n",
      "\u001b[0m12:15:06  25 of 44 START sql table model demo_gold.dim_broker ............................ [RUN]\n",
      "23/12/04 12:15:06 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m12:15:10  25 of 44 OK created sql table model demo_gold.dim_broker ....................... [\u001b[32mOK\u001b[0m in 4.32s]\n",
      "\u001b[0m12:15:10  26 of 44 START sql table model demo_gold.dim_date .............................. [RUN]\n",
      "23/12/04 12:15:10 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m12:15:12  26 of 44 OK created sql table model demo_gold.dim_date ......................... [\u001b[32mOK\u001b[0m in 1.70s]\n",
      "\u001b[0m12:15:12  27 of 44 START sql table model demo_gold.dim_company ........................... [RUN]\n",
      "23/12/04 12:15:12 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m12:15:15  27 of 44 OK created sql table model demo_gold.dim_company ...................... [\u001b[32mOK\u001b[0m in 3.16s]\n",
      "\u001b[0m12:15:15  28 of 44 START sql table model demo_silver.financials .......................... [RUN]\n",
      "23/12/04 12:15:15 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m12:16:19  28 of 44 OK created sql table model demo_silver.financials ..................... [\u001b[32mOK\u001b[0m in 64.28s]\n",
      "\u001b[0m12:16:19  29 of 44 START sql table model demo_silver.securities .......................... [RUN]\n",
      "23/12/04 12:16:20 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m12:16:25  29 of 44 OK created sql table model demo_silver.securities ..................... [\u001b[32mOK\u001b[0m in 5.83s]\n",
      "\u001b[0m12:16:25  30 of 44 START sql table model demo_silver.cash_transactions ................... [RUN]\n",
      "23/12/04 12:16:25 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m12:17:14  30 of 44 OK created sql table model demo_silver.cash_transactions .............. [\u001b[32mOK\u001b[0m in 48.27s]\n",
      "\u001b[0m12:17:14  31 of 44 START sql table model demo_gold.dim_customer .......................... [RUN]\n",
      "23/12/04 12:17:14 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m12:17:30  31 of 44 OK created sql table model demo_gold.dim_customer ..................... [\u001b[32mOK\u001b[0m in 16.44s]\n",
      "\u001b[0m12:17:30  32 of 44 START sql table model demo_gold.dim_trade ............................. [RUN]\n",
      "23/12/04 12:17:30 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m12:20:53  32 of 44 OK created sql table model demo_gold.dim_trade ........................ [\u001b[32mOK\u001b[0m in 202.74s]\n",
      "\u001b[0m12:20:53  33 of 44 START sql table model demo_silver.trades .............................. [RUN]\n",
      "23/12/04 12:20:53 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m12:24:29  33 of 44 OK created sql table model demo_silver.trades ......................... [\u001b[32mOK\u001b[0m in 216.65s]\n",
      "\u001b[0m12:24:29  34 of 44 START sql table model demo_gold.dim_security .......................... [RUN]\n",
      "23/12/04 12:24:30 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m12:24:33  34 of 44 OK created sql table model demo_gold.dim_security ..................... [\u001b[32mOK\u001b[0m in 3.62s]\n",
      "\u001b[0m12:24:33  35 of 44 START sql table model demo_silver.watches_history ..................... [RUN]\n",
      "23/12/04 12:24:33 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m12:29:09  35 of 44 OK created sql table model demo_silver.watches_history ................ [\u001b[32mOK\u001b[0m in 276.39s]\n",
      "\u001b[0m12:29:10  36 of 44 START sql table model demo_gold.dim_account ........................... [RUN]\n",
      "23/12/04 12:29:10 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m12:29:49  36 of 44 OK created sql table model demo_gold.dim_account ...................... [\u001b[32mOK\u001b[0m in 39.23s]\n",
      "\u001b[0m12:29:49  37 of 44 START sql table model demo_silver.holdings_history .................... [RUN]\n",
      "23/12/04 12:29:49 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
      "\u001b[0m12:33:35  37 of 44 OK created sql table model demo_silver.holdings_history ............... [\u001b[32mOK\u001b[0m in 226.36s]\n",
      "\u001b[0m12:33:35  38 of 44 START sql table model demo_gold.fact_market_history ................... [RUN]\n",
      "23/12/04 12:33:35 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd $REPO_ROOT\n",
    "dbt run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae93304-68eb-46c8-86a3-26feec06a54a",
   "metadata": {},
   "source": [
    "## Run dbt tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b563f4-0b31-40a3-b353-9e6c9de8c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd $REPO_ROOT\n",
    "dbt test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ce00fe-ce46-4202-a798-a7f227ff3c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TBD-TPC-DI-setup\") \\\n",
    "    .master(\"yarn\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c892605-9496-4526-b574-a19168678934",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"show databases\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e94c83-4983-49f5-8597-77e3b9c4661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"use demp_gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44296edd-82e6-4600-b730-d2cc4992a81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e34fa44-084c-4445-ad41-17b4762a0446",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c190b0c0-b4e2-4aed-85aa-1b78b77d1c05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
